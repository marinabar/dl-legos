{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOdEMal4Zgx0LDIku/k6PnX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The Pursuit of Human Labeling: A New Perspective on Unsupervised Learning"
      ],
      "metadata": {
        "id": "yr0rDrIBi4I5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A new approach to unsupervised classification based on existing vision models"
      ],
      "metadata": {
        "id": "ESojbm-PifZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of the research paper published by Artyom Gadetsky and Maria Brbic from the EPFL AI Reasearch Center. The abstract can be found [here](https://openreview.net/pdf?id=3GpIeVYw8X)."
      ],
      "metadata": {
        "id": "7deGeYjuiMhX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Approach** : Human labeled points are linearly separable in a sufficiently strong\n",
        "representation space, and are invariant to the underlying model and resulting representation space."
      ],
      "metadata": {
        "id": "JmFiA1x6jNmi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8lb9gZhVVcm"
      },
      "outputs": [],
      "source": [
        "!wget https://brbiclab.epfl.ch/wp-content/uploads/2023/11/data.zip\n",
        "!unzip data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "\n",
        "phi2model=torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
        "\n",
        "phi2model.eval()\n",
        "statedict=phi2model.state_dict()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7KMbEYAIUI3",
        "outputId": "177109d6-e56c-4458-bcbc-7bd0fd62cdcb"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
            "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
            "  warnings.warn(\"xFormers is not available (Attention)\")\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
            "  warnings.warn(\"xFormers is not available (Block)\")\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vits14/dinov2_vits14_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov2_vits14_pretrain.pth\n",
            "100%|██████████| 84.2M/84.2M [00:00<00:00, 228MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to numpy\n",
        "numpy_params = {key: value.numpy() for key, value in statedict.items()}\n",
        "#save npy file\n",
        "np.save('dinov2basic.npy', numpy_params)"
      ],
      "metadata": {
        "id": "1XdydVGBJJcn"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the First representation"
      ],
      "metadata": {
        "id": "EniyMDhPLLcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finetuned on CIFAR10"
      ],
      "metadata": {
        "id": "9PYYFzWQLPx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install timm"
      ],
      "metadata": {
        "id": "6T-8Yo0QLbXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "LKCiqzJ0HkHQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import models\n",
        "\n",
        "\n",
        "# create a transform class for applying the normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # normalize the representations to have unit norm\n",
        "])"
      ],
      "metadata": {
        "id": "6ndJJn6PJPC-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "train_dataset = CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = CIFAR10(root='./data', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "id": "JuzGgwlLLZgP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313ed4f6-1470-40e6-836c-48c64d0c39f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 13064179.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "o2vsxF_LLrCe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda')"
      ],
      "metadata": {
        "id": "JHhW_JyRRxqB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFb0UXd1R7Kx",
        "outputId": "3dfb70f7-db74-458f-d56d-2eb12a701d69"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to check the architecture of the chosen model and modify the last layer according to the original layer in the head"
      ],
      "metadata": {
        "id": "_sb9IrpVPeJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "resnet = models.resnet50(True)\n",
        "vgg16=models.vgg16(True)\n",
        "num_classes = 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mTL9YmtLukF",
        "outputId": "48d209bc-eec4-4012-cc5e-5af098e6d3e3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:07<00:00, 75.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in resnet.named_parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "JXSklTRjOt1_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in vgg16.named_parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "YcmUPP1NPec4"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)"
      ],
      "metadata": {
        "id": "c3pOlgvfbIIK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16.classifier[6] = nn.Linear(vgg16.classifier[6].in_features,10)"
      ],
      "metadata": {
        "id": "FaPvJOP7PldP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in vgg16.named_parameters():\n",
        "  print(name, param.requires_grad)"
      ],
      "metadata": {
        "id": "U5FMPKGBlp5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet=resnet.to(device)"
      ],
      "metadata": {
        "id": "wNFVliPCR_nK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16=vgg16.to(device)"
      ],
      "metadata": {
        "id": "auP_BoxQPwA_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(vgg16.parameters(), lr = 0.001, momentum=0.9, weight_decay=0.0001)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "2fgv0AdfP3Gz"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "  vgg16.train()\n",
        "  for images, labels in train_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = vgg16(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}')\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "  vgg16.eval()\n",
        "  total_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = vgg16(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      total_loss += loss.item() * labels.size(0)\n",
        "      total += labels.size(0)\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "  average = total_loss / total\n",
        "  print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {average:.4f}')\n",
        "  accuracy = correct / total\n",
        "  print(f'Epoch [{epoch+1}/{num_epochs}], Test Accuracy: {100 * accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "5jBq-7w-PEHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16.to(\"cpu\")\n",
        "vgg16.eval()\n",
        "# sae the model state\n",
        "state_dictphi1 = vgg16.state_dict()\n",
        "\n",
        "tonumpystate= {key: value.numpy() for key, value in state_dictphi1.items()}\n",
        "\n",
        "# Save the NumPy parameters to a .npy file\n",
        "np.save('vgg16cifar10.npy', tonumpystate)"
      ],
      "metadata": {
        "id": "DTVH9KWYRyzw"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}